\section{Universality and Representability}

Let $\mcC$ be a category. We now identify some special, or \emph{universal}, objects of $\mcC$. 

\begin{dfn}
We say $0$ is the \emph{initial object} of $\mcC$ if for any $\mcC$-object---including itself---$X$, there exists a unique arrow $0\to X$. Dually, we say $1$ is the \emph{terminal object} of $\mcC$ if for any $\mcC$-object $X$, there exists a unique arrow $X\to 1$.
\end{dfn}

By duality, an initial object in $\mcC$ is a terminal object in $\mcC\op$ and vice versa. When $\mcC$ is thin, i.e. a preorder, the bottom $\bot$ is the initial object and top $\top$ is the terminal object. From this observation, we remark that not all categories have initial or terminal objects---for example, the poset $(\ZZ,\leq)$, thought of as a thin category, has neither top nor bottom and hence neither initial nor terminal object. We often denote the unique arrow guaranteed by universality via a dashed line:
\[
\begin{tikzcd}
0 \arrow[r,dashed] & S
\end{tikzcd}
\]
The use of the symbols $0$ and $1$ for generic initial and terminal objects is inspired by the fact that $\mathbf{0}=\varnothing$ and $\mathbf{1}\cong\star$ are respectively the initial and terminal objects in $\Set$. The latter fact is easier to see: given a set $S$, a map $S\to\star$ consists of a choice of element in $\star$ for every $s\in S$---but there can be only one such choice: the sole element $*\in\star$. In turn, one can conceptualize the fact that $\varnothing$ is the initial object in $\Set$ by considering the fact that a map $\varnothing\to S$ consists of a choice for every element in $\varnothing$---but there are no such elements, and hence no choice needs to be made. Said otherwise, each element of the domain poses a challenge: to choose a single codomain element associated with it. In the case that there are no such challenges, we say---via some combination of philosophy and convention---that there is hence precisely one map that is gifted to us by a lack of choice in the matter. This is in some sense analogous to the situation in which we define nullary operators to be units.

In the context of $\Pre$, the initial and terminal objects are, just as in $\Set$, $\varnothing$ and $\star$, equipped with the unique ordering structure on them. This turns out to be no coincidence: $\Pre$---and similarly $\Pos$---inherit much of their ``universal structure'' from $\Set$. This will be elaborated further in the subsequent section.

In both $\Mon$ and $\Vect_k$ we have a so called \emph{zero object}---i.e. an object that is both terminal and initial. These are respectively given by the one element monoid $\{e\}$ and the zero vector space $\{0\}$. At the risk of mild notational overload, we will denote both of these by $0$. These are terminal objects for the same reason that $\star$ is a terminal object in $\mcC$---every homormorphism to the one element structure maps the entire codomain to that element. Just as above, this arises from the fact that half of the universal structure of $\Set$ is inherited by $\Mon$ and $\Vect_k$. In turn, however, the initial object is not the empty set! This is because both monoids and vector spaces require unit elements. The arrows from these one element structures to any other structure are unique by virtue of the fact that these arrows by definition must preserve unit elements, and hence uniquely send the sole domain element to the unit of the codomain.

We now present the first special property of universal objects.

\begin{prop} Let $0$ and $0'$ be initial objects of $\mcC$. Then $0\cong0'$. 
\end{prop}
\begin{proof}
By initiality, there are unique arrows $0\to 0$ and $0'\to 0'$, which must be the identity arrows $\Id{0}$ and $\Id{0'}$. We also have unique arrows $\varphi:0\to 0'$ and $\varphi':0'\to 0$. This yields arrows $\varphi\then\varphi':0\to 0$ and $\varphi'\then\varphi:0'\to0$, which, by uniqeueness, must be the respective identity arrows.
\end{proof}

By duality, the same fact holds for terminal objects. In fact, we will see throughout the section that any universal construction can be cast as an initial object in some category, and hence enjoys the result of this theorem.

As the title suggests, we will also consider a second approach, called representability, towards the study of categories. In particular, we say a functor $F:\mcC\to\Set$ is \emph{representable} if there is a natural isomorphism $F\cong\mcC(c,-)$ for some $\mcC$-object $c$. Dually, we say a functor  $F:\mcC\op\to\Set$ is representable if there is a natural isomorphism $F\cong\mcC(-,c)$ for some $\mcC$-object $c$. In both of these cases, we say that $c$ \emph{represents} the relevant functor. In turn, the functor that an object represents will often provide a semantic interpretation for the object. A particularly important example of reprsentable functor is the identity functor $\Id{\Set}:\Set\to\Set$. Recalling that an element $s\in S$ is equivalent to the arrow $\lambda*.s:\star\to S$, we have that $S\cong\Set(\star, S)$, and hence that $\Id{\Set}\cong\Set(\star,-)$. 

Universal constructions always have an interpretation in the language of representability. In the case of initial and terminal objects, this may seem a little dull. In particular, consider the constant functor $\mcC\to\Set$ that sends every object to $\star$ and every arrow to $\Id{\star}$. If $\mcC$ has an initial object $0$, then this functor is naturally isomorphic to $\mcC(0,-)$ since by definition the set of arrows $0\to X$ for any $X$ is a singleton. Dually, the constant functor $\mcC\op\to\Set$ with the same behavior is naturally isomorphic to $\mcC(-,1)$. The contravariance, although not necessary to the well definedness of this particular functor, is stiuplated to respect the fact that $\mcC(-,c)$ is generically contravariant.

Representable functors are special because of the \emph{Yoneda Lemma}, the most famous result in category theory.

\begin{thm} Let $\mcC$ be a category, $c\in|\mcC|$, and $F:\mcC\to\Set$. Then there is a natural bijection
\[\Cat(\mcC(c,-),F)\cong Fc\]
given by mapping a natural transformation $T:\mcC(c,-)\to F$ to $T_c(\Id{c})\in Fc$.
\end{thm}

\begin{proof}
Let $\Phi:\Cat(\mcC(c,-),F)\to Fc::T\mapsto T(\Id{c})$. We will now construct a map $\Psi: F(c)\to \Cat(\mcC(c,-),F)$ that satisfies $\Phi\circ\Psi=\Id{Fc}$ and $\Psi\circ\Phi=\Id{\Cat(\mcC(c,-),F)}$.

We define $\Psi$ to be a valid inverse by mapping an element $x$ of $Fc$ to a natural transformation $T$ for which $T_c(\Id{c})=x$. We now show that this uniquely defines a natural transformation. Since $T$ consists of component maps $T_{c'}:\mcC(c,c')\to Fc$ for all $c'$, it suffices to define $T_{c'}(f)$ for all $f\in\mcC(c, c')$. Then, letting $f\in\mcC(c,c')$, the naturality condition states that the following square must commute.
\[
\begin{tikzcd}
\mcC(c,c) \arrow[r,"T_c"] \arrow[d,"-\then f"'] & Fc \arrow[d,"Ff"] \\
\mcC(c,c') \arrow[r,"T_{c'}"'] & Fc'
\end{tikzcd}
\]
Tracing the two paths of the identity arrow $\Id{c}\in\mcC(c,c)$, we have:
\begin{align*}
    \to\downarrow &: \Id{c}\mapsto T_c(\Id{c})=x\mapsto (Ff)x \\
    \downarrow\to &: \Id{c}\mapsto f\mapsto T_{c'}(f)
\end{align*}
This then forces us to define $T_{c'}(f)=(Ff)x$.
\end{proof}

The reader is encouraged to check that this bijection is natural in $c$. Furthermore, this bijection is natural in $\mcC$ and $F$, but this involves slightly more mental and notational contortion to articulate. Note that, were we to apply the Yoneda Lemma to $\mcC\op$, we would have that for any $F:\mcC\op\to\Set$ and $c\in|\mcC|$:
\[\Cat(\mcC\op(c,-),F)=\Cat(\mcC(-,c),F)\cong Fc.\]
The Yoneda Lemma can be used to answer questions like ``what are the natural maps $X\to\Set(S,X)$?'' Said both more suggestively and formally: what are the natural transformations $\Id{\Set}\cong\Set(\star,-)\to\Set(S,-)$? The Yoneda Lemma states that these would be in natural bijection with elements of the set $\Set(S,\star)$, which, by the terminality of $\star$, form a singleton given by the constant map. Hence the only natural transformation $T:\Id{\Set}\to\Set(S,-)$ would be defined by extending $T_{\star}:\star\to\Set(S,\star)::\Id{\star}\mapsto \lambda s.*:S$. Hence, applying the bijection given by the Yoneda Lemma, we have, for a set $X$ and $X$-element $x$, i.e. arrow $x:\star\to X$, that: \[T_X(x)=\Set(S,x):\Set(S,\star)\to\Set(S,X)::f\mapsto x.\]
Said more plainly, a natural map $\Set(\star,X)\to\Set(S,X)$ is just a precomposition with the map $x:\star\to S$, i.e. a map that sends the element $x\in X$ to the constant map $\lambda s.x: S\to X$. This then allows us to conclude that the only natural map---i.e. the only map that can be defined generically, with no reference to the sets involved---$X\to\Set(S,X)$ is the map that takes elements $x\in X$ to constant maps $S\to X$ that send each $S$-element to $x$.

This example involved the case that the functor $F$ was itself representable. In this context, the Yoneda Lemma has another meaningful interpretation. Define the functor $\mathcal{Y}$, called the \emph{Yoneda embedding}, of type $\mcC\op\to\Cat(\mcC,\Set)$ as follows. For an object $c$, define $\mathcal{Y}c=\mcC(c,-)$. For an arrow $\varphi : c\to c'$, define the natural transformation $\mathcal{Y}\varphi:\mcC(c',-)\to\mcC(c,-)$ via the components \[[\mathcal{Y}\varphi]_X:\mcC(c',X)\to\mcC(c,X)::f\mapsto \varphi\then f.\]
Then, the Yoneda lemma states that
\[\Cat(\mathcal{Y}c',\mathcal{Y}c)=\Cat(\mcC(c',-),\mcC(c,-))\cong\mcC(c,c').\]
This can be interpreted as the statement that the Yoneda embedding $\mathcal{Y}$ is fully faithful; i.e. that $\mathcal{Y}_{c',c}:\mcC\op(c',c)=\mcC(c,c')\to\Cat(\mathcal{Y} c',\mathcal{Y} c)$ is always a bijection. Recall that this means that $\mathcal{Y}$ has the property that if $\mathcal{Y}c\cong\mathcal{Y}c'$, then $c\cong c'$. This has the deep implication that an object is determined up to isomorphism by the functor it represents. This truth is in some sense why category theory contributes insight to mathematics beyond mere bookkeeping: rather, it allows one to speak of mathematical structures purely in terms of their relationships to all other structures of their kind, as opposed to relying on what they're ``made of.'' As an example of this principle, consider the case of initial objects: since these always represent the constant set-valued functor of value $\star$, they must all be isomorphic.

Let's now consider a more interesting dual pair of universal constructions. We motivate these with a case study in the context of $\Set$. Consider a map $\varphi:S\to X\times Y$; for example, perhaps $S$ consists of the set of points in some island, $X$ and $Y$ respectively denote the sets of possible values for temperature and pressure, and $\varphi$ assigns to each point the ordered pair of air temperature and pressure at the altitude of an average human height. We can easily extract from this map two maps $\varphi_X$ and $\varphi_Y$, which respectively report the temperature and the pressure. Intuitively, $\varphi_X$ merely forgets the pressure data and $\varphi_Y$ merely forgets the temperature data. More formally, we can define $\varphi_X=\varphi\then\pi_X$, where we call $\pi_X$ the \emph{projection} map, and define it by the rule $(x,y)\mapsto x$. Doing the same for $Y$, we note the following:
\[\varphi s =(\varphi_X(s),\varphi_Y(s))\]
Said otherwise, from a map $\varphi\in\Set(S,X\times Y)$, we can extract the pair of maps $(\varphi\then \pi_X,\varphi\then \pi_Y)\in\Set(S,X)\times\Set(S,Y)$, and, from a pair of maps $(\varphi_X,\varphi_Y)\in\Set(S,X)\times\Set(S,Y)$, we can extract the map $\lambda s.(\varphi_Xs,\varphi_Ys)\in\Set(S,X\times Y)$. Furthermore, this correspondence yields a bijection
\[\Set(S,X\times Y)\cong\Set(S,X)\times\Set(S,Y).\]
Diagrammatically, this is often expressed as follows:
\[
\begin{tikzcd}
& S \arrow[d,"\varphi", dashed] \arrow[ddl,"\varphi_X"'] \arrow[ddr,"\varphi_Y"] & \\
& X\times Y \arrow[dl,"\pi_X"] \arrow[dr,"\pi_Y"'] &\\
X & & Y
\end{tikzcd}
\]
The dashed arrow is read as follows: given a pair $(\varphi_X:S\to X,\varphi_Y:S\to Y)$, there exists a unique arrow $\varphi:S\to X\times Y$ making the diagram commute. This diagram also states that---following the existence of compositions---that, given a $\varphi$, composing it with the projections yields a pair $(\varphi_X:S\to X,\varphi_Y:S\to Y)$. The bijection and the diagram respectively characterize the universality and representability features of the Cartesian Product.

More generally, given a category $\mcC$ and two objects $X_i$ for $i=0,1$, the \emph{product} $X_0\times X_1$, if it exists, is an object equipped with projection arrows $\pi_i:X_0\times X_1\to X_i$ for $i=0,1$, such that, given another object $S$ and a pair of arrows $\varphi_i:S\to X_i$ for $i=0,1$, there exists a unique arrow $\varphi:S\to X_0\times X_1$ making the following diagram in $\mcC$ commute:
\[
\begin{tikzcd}
& S \arrow[d,"\varphi", dashed] \arrow[ddl,"\varphi_{0}"'] \arrow[ddr,"\varphi_{1}"] & \\
& X_0\times X_1 \arrow[dl,"\pi_{0}"] \arrow[dr,"\pi_{1}"'] &\\
X_0 & & X_1
\end{tikzcd}
\]
The product $X_0\times X_1$ then satisfies the natural bijection:
\[\mcC(-,X_0\times X_1)\cong\mcC(-,X_0)\times\mcC(-,X_1).\]
We can encode this even more tightly as a terminal object or a representable functor. Letting $X_0,X_1$ be objects of $\mcC$, define the category ${\mcC}/(X_0,X_1)$ as having objects \emph{cones}, i.e. triples $(A,f_0,f_1)$ where $A$ is a $\mcC$-object and $f_i:A\to X_i$ for $i=0,1$ are $\mcC$-arrows. We call $A$ the \emph{apex} and the  $f_i$'s the \emph{legs}. Arrows $(A,f_0,f_1)\to (A',f'_0,f'_1)$ are simply $\mcC$-arrows $\varphi:A\to A'$ for which the following diagram commutes:
\[
\begin{tikzcd}
A \arrow[rrr,"\varphi"] \arrow[dr,"f_0"'] \arrow[drr,"f_1"] &&& A' \arrow[dl,"f'_1"] \arrow[dll,"f'_0"'] \\
& X_0 & X_1 &
\end{tikzcd}
\]
The triple $(X_0\times X_1,\pi_0,\pi_1)$ is then the terminal object in $\mcC/(X_0,X_1)$. This merely reformulates the diagram we used to define products since there $(S,\varphi_0,\varphi_1)$ was a cone and we stipulated that it had a unique cone arrow to $(X_0\times X_1,\pi_0,\pi_1)$---this is precisely what it meant to be a terminal object! Since they are terminal objects, we automatically have that products are unique up to isomorphism---where this isomorphism is itself the unique one that consists of arrows that commute with projections. The cone constructions also allows us to codify the representability perspective of the product. More precisely, let $\Cone_{(X_0,X_1)}:\mcC\op\to\Set$ map a $\mcC$-object $A$ to the set of cones, i.e. objects of $\mcC/(X_0,X_1)$, with apex $A$. Furthermore, it maps a $\mcC$-arrow $\varphi:A\to A'$ to the set map $(A',f_0,f_1)\mapsto (A,\varphi\then f_0,\varphi\then f_1)$. We then have that this functor is represented by the product $X_0\times X_1$; i.e. we have the following natural isomorphism:
\[\Cone_{(X_0,X_1)}\cong \mcC(-,X_0\times X_1)\]
This is the case, since, as our definition established: a cone over $X_0,X_1$ is naturally equivalent to an arrow to the product $X_0\times X_1$.

We now consider the dual case: consider a set map $\psi:R+S\to X$, e.g. if $R$ and $S$ represent the set of points on two different islands---and hence their disjoint union $R+S$ represents the set of points across both islands, $X$ the set of possible temperatures, and $\psi$ a map assigning a point its temperature. Dually to the previous example, we can split this up into a pair $(\psi_R:R\to X,\psi_S:S\to X)$, corresponding to the temperature maps for each individual island. Just as before, this yields a natural bijection:
\[\Set(R+S,X)\cong\Set(R,X)\times\Set(S,X).\]
Just as composing with the projection maps allows for decomposing maps into a product, precomposing with so called \emph{inclusion maps} allows for decomposing maps out of a disjoint union. More specifically the inclusion map $\iota_R:R\to R+S$ is given by the inert rule $r\mapsto r$, which merely changes the ambient setting within which the element is considered. Then we have that $\psi_R = \iota_R\then\psi$, and similarly for $S$.

More generally, given a category $\mcC$ and two objects $X_i$ for $i=0,1$, the \emph{coproduct} or \emph{sum} $X_0+X_1$, if it exists, is merely the product in $\mcC\op$. Thus it is an object equipped with inclusion arrows $\iota_i:X_i\to X_0+ X_1$ for $i=0,1$, such that, given another object $S$ and a pair of arrows $\varphi_i:X_i\to S$ for $i=0,1$, there exists a unique arrow $\varphi: X_0+X_1\to S$ making the following diagram in $\mcC$ commute:
\[
\begin{tikzcd}
& S & \\
& X_0\times X_1 \arrow[u,"\varphi"', dashed]  &\\
X_0 \arrow[ur,"\iota_{0}"']  \arrow[uur,"\varphi_{0}"] & & X_1  \arrow[ul,"\iota_{1}"] \arrow[uul,"\varphi_{1}"']
\end{tikzcd}
\]
The coproduct $X_0+ X_1$ then satisfies the natural bijection:
\[\mcC(X_0+ X_1,-)\cong\mcC(X_0,-)\times\mcC(X_1,-).\]
We can encode this even more tightly as an initial object or a representable functor. Letting $X_0,X_1$ be objects of $\mcC$, define the category $(X_0,X_1)/\mcC$ as having objects \emph{cocones}, i.e. triples $(A,f_0,f_1)$ where $A$ is a $\mcC$-object and $f_i:X_i\to A$ for $i=0,1$ are $\mcC$-arrows. We still call $A$ the apex (but, if you're a stickler for symmetry, feel free to call it the \emph{nadir}) and the  $\iota_i$'s the legs (or \emph{arms}). Arrows $(A,f_0,f_1)\to (A',f'_0,f'_1)$ are simply $\mcC$-arrows $\varphi:A\to A'$ for which the following diagram commutes:
\[
\begin{tikzcd}
A \arrow[rrr,"\varphi"]   &&& A'   \\
& X_0 \arrow[ul,"f_0"] \arrow[urr,"f'_0"] & X_1 \arrow[ur,"f'_1"'] \arrow[ull,"f_1"'] &
\end{tikzcd}
\]
The triple $(X_0+ X_1,\iota_0,\iota_1)$ is then the initial object in $(X_0,X_1)/\mcC$. This merely reformulates the diagram we used to define coproducts since there $(S,\varphi_0,\varphi_1)$ was a cocone and we stipulated that it had a unique cocone arrow from $(X_0+ X_1,\iota_0,\iota_1)$---this is precisely what it meant to be an initial object! Again, we automatically have that coproducts are unique up to canonical isomorphism. The cocone constructions also allows us to codify the representability perspective of the coproduct. More precisely, let $\Cocone_{(X_0,X_1)}:\mcC\to\Set$ map a $\mcC$-object $A$ to the set of cocones, i.e. objects of $(X_0,X_1)/\mcC$, with apex $A$. Furthermore, it maps a $\mcC$-arrow $\varphi:A\to A'$ to the set map $(A,f_0,f_1)\mapsto (A', f_0\then\varphi, f_1 \then\varphi)$. We then have that this functor is represented by the coproduct $X_0+ X_1$; i.e. we have the following isomorphism:
\[\Cocone_{(X_0,X_1)}\cong \mcC(X_0+X_1,-)\]
This is the case, since, as our definition established: a cocone under $X_0,X_1$ is naturally equivalent to an arrow from the coproduct $X_0+X_1$.

We note that, in the context of a thin category, i.e. preorder, $\ol{P}$ we had that the meet $x\wedge y$ satisfied, in arrow notation:
\[t\to x\wedge y\Leftrightarrow t\to x, t\to y,\]
I.e. we have the natural bijection
\[\ol{P}(t,x\wedge y)\cong \ol{P}(t,x)\times\ol{P}(t,y)\]
Hence the meet is a just a product, and, by duality, a join is just a coproduct.

Now, zooming out, let's consider products and coproducts in $\Pre$. Recall that $\Pre$ inherited its initial and terminal object from $\Set$ for deep reasons we put off until the next section. For the same reason, this will also turn out to hold for products and coproducts! Our work isn't necessarily finished, though: it may be the case, as we'll show, that the underlying set of the product of two preorders is the Cartesian product of their underlying sets, but we still need to describe what the ordering is on this set---and the same for coproducts. This wasn't necessary before, simply because the initial object $\varnothing$ and terminal object $\star$ had a unique ordering. We start with the coproduct because it is more simple. More precisely, given preorders $(P_i,\preceq_i)$ for $i=0,1$, we define their coproduct $(P_0+P_1,\preceq)$ by
\[\preceq(p,q) = \begin{cases} \preceq_i(p,q) & p,q\in P_i \\ \bot & \text{otherwise}\end{cases}\]
Said otherwise, if $p$ and $q$ belong to the same summand, then we merely relate them as we did before; otherwise, we do not relate them. This automatically makes the set inclusion maps $\iota_i:P_i\to P_0+P_1$ monotonic since $p\preceq_i q\Rightarrow \iota_i(p)\preceq\iota_i(q)$. Furthermore, given a pair of monotone maps $\varphi_i:(P_i,\preceq_i)\to(Q,\sqsubseteq)$, this automatically assembled into a monotone map 
\[\varphi_0+\varphi_1:(P_0+P_1,\preceq)\to(Q,\sqsubseteq)\] defined by $p\mapsto \varphi_i(p)$ for $p\in P_i$. This is automatically monotone since we needn't concern ourselves with preserving cross-summand relations! This vacuousness of satisfying property is at the heart of a universal construction. We now define the product to satisfy the dual condition: i.e. component maps should be vacuously combinable into a monotone map to the product. Towards this end, given  preorders $(P_i,\preceq_i)$ for $i=0,1$, we define their product $(P_0\times P_1,\preceq)$ as
\[\preceq((p_0,q_0),(p_1,q_1))=\begin{cases}\top & [p_0\preceq_0 q_0]\wedge [p_1\preceq_1 q_1] \\ \bot & \text{otherwise} \end{cases}\]
Said otherwise, two ordered pairs $(p_i,q_i)$ are related if and only if both of their respective components had been related. This allows projections to be vacuously monotone since $(p_0,p_1)\preceq (q_0,q_1)\Rightarrow p_i\preceq_i q_i$; and, furthermore, given monotone maps $\varphi_i:(Q,\sqsubseteq)\to (P_i,\preceq_i)$, this automatically assembles into a monotone map
\[\varphi_0\times\varphi_1:(Q,\sqsubseteq)\to(P_0\times P_1,\preceq)::q\mapsto (\varphi_0q,\varphi_1q)\]
since $q\sqsubseteq q'\Rightarrow\forall i:\varphi_i(q)\preceq_i\varphi_i(q')\Rightarrow \varphi(q)\preceq\varphi(q')$. 

We now use these constructions to investigate the products and coproducts in the subcategories $\Pos$ and $\Tot$. Before exploring them, we note that, if these categories have products or coproducts, then these must be the same as those constructed in $\Pre$. This property is often referred to as \emph{reflection} of products and coproducts, and is due to the following result.

\begin{prop}
Fully faithful functors reflect products. Formally, let $F:\mcC\to\mcD$ be a fully faithful functor, $d_0,d_1$ be $\mcD$-objects with product $d_0\times d_1$, and $c_0,c_1$ be $\mcC$-objects for which $Fc_i=d_i$. Then, if $c_0\times c_1$ exists, $F(c_0\times c_1)=d_0\times d_1$. 
\end{prop}
\begin{proof}
Let $c\in|\mcC|$. Then consider the sequence of isomorphisms
\begin{align*}
    \mcD(Fc,d_0\times d_1)& \cong\mcD(Fc,d_0)\times\mcD(Fc,d_1)\\
    &\cong \mcC(c,c_0)\times\mcC(c,c_1) \\
    & \cong\mcC(c,c_0\times c_1) \\
    &\cong \mcD(Fc,F(c_0\times c_1))
\end{align*}
Since this did not rely on $c$, this gives the isomorphism of representable functors:
\[\mcD(-,d_0\times d_1)\cong\mcD(-,F(c_0\times c_1))\]
The full-faithfuness of the Yoneda embedding then implies the desired isomorphism \[F(c_0\times c_1)\cong d_0\times d_1. \qedhere\]
\end{proof}
Since full-faithfulness does not rely on arrow orientation, duality gives us that fully faithful functors also reflect coproducts. Thus, to study products and coproducts in $\Pos$ and $\Tot$, it suffices to check that the products and coproducts defined in $\Pre$ preserve posetality and totality of their components.

In the case of $\Pos$ both products and coproducts defined in $\Pre$ turn out to be products and coproducts in $\Pos$. To see this, we check that if $(P_i,\preceq_i)$ are both posetal, then their product and coproduct is also posetal. Recall that posetality merely requires the antisymmetry condition: $x\preceq y, y\preceq x\Leftrightarrow x=y$. Since coproducts do not add any cross-summand relations, we receive no candidate pairs $p_i\in P_i$ for which $p_0\preceq p_1$ or vice versa, and hence we automatically have that the preorder coproduct is also a poset. Now consider the product $(P_0\times P_1,\preceq)$ and suppose $(p_0,p_1)\preceq (q_0,q_1)$ and $(q_0,q_1)\preceq(p_0,p_1)$ and hence that $p_i\preceq_i q_i$ and $q_i\preceq_i p_i$, thus, by the posetality of the factors, forcing $p_i=q_i$. Therefore $\Pos$ inherits both its product and coproduct from $\Pre$.

It is easy to see, in contrast, that the same doesn't hold for $\Tot$. Since total orders require that for any pair $p,q$ either $p\preceq q$ or $q\preceq p$, the coproduct of non-empty total orders is never a total order since we have no relations across summands. The same goes for products, and this is perhaps best exemplified with the example of $(\ZZ\times\ZZ,\leq)$---there's no way to compare $(3,5)$ and $(5,3)$, and hence products of total orders are typically not total.

Just as it did its terminal object, the category $\Mon$ inherits products from $\Set$. More precisely, given monoids $(M_i,\odot_i,e_i)$ for $i=0,1$, we define their product as $(M_0\times M_1,\odot,(e_0,e_1))$, where $\odot$ is defined component-wise:
\[(m_0,m_1)\odot(n_0,n_1)=(m_0\odot_0 n_0,m_1\odot_1 n_1).\]
It is a straightforward exercise to check that this satisfies the monoid axioms. The projection maps preserve the operation since
\[\pi_i((m_0,m_1)\odot(n_0,n_1))=\pi_i(m_0\odot_0 n_0,m_1\odot_1 n_1) = m_i\odot_i n_i.\]
Similarly, two monoid homomorphisms $\varphi_i:N\to M_i$ vacuously assemble into a monoid homormorphism $\varphi$ defined by $n\mapsto (\varphi_0 n,\varphi_1 n)$ since 
\begin{align*}
    \varphi(n\odot n') &= (\varphi_0(n\odot n'),\varphi_1(n\odot n')) \\
    &= (\varphi_0n\odot_0\varphi_0 n', \varphi_1n\odot_1\varphi_1 n') \\
    &= (\varphi_0 n,\varphi_1 n)\odot (\varphi_0 n',\varphi_1 n') \\
    &= \varphi(n)\odot \varphi(n').
\end{align*}
The analogous identity can be checked for unit elements. The coproduct of monoids, however, looks different from what we've seen thus far, but is related to the free monoid construction. More explicitly, given monoids $(M_i,\odot_i,e_i)$, we define their \emph{free product} $(M_0*M_1,\odot,e)$ as follows. Let $M_0*M_1$ be the set of all words of alternating $M_0$ and $M_1$ non-unit elements with $\varnothing$ the empty word. Using superscripts to denote which monoid each element comes from, what follows are some $M_0*M_1$ elements.
\[x^0y^1z^0, x^1y^0x^1z^0, \varnothing\]
We note that these can start or end with a term from either $M_0$ or $M_1$, can include repeated elements, and can be of any finite length with the unique zero length word serving as the unit element. Since the unit element of any monoid is unique, we have to fuse the two monoids' units into a single unit. Since this is the case, we had to exclude units from our words since these could be absorbed into the element to their right or left. We will later see a more elegant characterization of this set.

Finally, we define the product $w\odot w'$ of two words $w,w'$ as follows. If the final term of $w$ and the first term of $w'$ come from distinct monoids, then this product is merely the concatenation of the two words. If, in contrast, these two terms come from the same monoid, then we first concatenate the two lists, but then, so as to preserve alternation, replace these two adjacent elements with their product in the respective monoid to which they both belong. Towards greater formality, let $h(w)$ and $t(w)$ denote the first and last letter of $w$, respectively, and let $\ol{h}(w)$ and $\ol{t}(w)$ respectively denote \emph{all but} the first and last term of $w$. Letting $;$ denote concatenation, we have $w=h(w);\ol{h}(w)=\ol{t}(w);t(w)$, and hence define $\odot$ by
\[w\odot w'=\begin{cases} \ol{t}(w);t(w)\odot_i h(w');\ol{h}(w') & t(w),h(w')\in M_i \\ w;w' & \text{otherwise} \end{cases}\]
Note that, in the case of singleton words coming from the same monoid, this is merely their product in that monoid. We now define the inclusion maps $\iota_i:M_i\to M$ as sending non-unit elements to their corresponding singleton words, and sending the unit element to the empty word. These are homomorphisms since we do not alter the elements, merely recast them as words. Finally, given two monoid homomorphisms $\varphi_i:M_i\to N$, we show that these vacuously assemble into a monoid homomorphism $\varphi$ defined term-wise. More precisely, $\varphi(a;b)=\varphi(a);\varphi(b)$, where, so as to respect the inclusion maps, we define $\varphi(a)=\varphi_i(a)$ for $a\in M_i$. This map automatically preserves products $w\odot w'$ when these equal $w;w'$. In the other case, i.e. when $t(w),h(w')\in M_i$, we have:
\begin{align*}
    \varphi(w\odot w')&=\varphi(\ol{t}(w);t(w)\odot_i h(w');\ol{h}(w')) \\
    &=\varphi\ol{t}(w);\varphi_i[t(w)\odot_i h(w')];\varphi\ol{h}(w') \\
    &= \varphi\ol{t}(w);\varphi_it(w)\odot_i\varphi_i h(w');\varphi\ol{h}(w') \\
    &= \varphi\ol{t}(w);\varphi t(w)\odot_i\varphi h(w');\varphi\ol{h}(w') \\
    &= \varphi(\ol{t}(w);t(w))\odot \varphi(h(w')\ol{h}(w)) \\
    &= \varphi w\odot \varphi w'
\end{align*}
Finally, we define $\varphi\varnothing=e_N$. The reader can check that this plays well with the computation above.

The product and coproduct of vector spaces is particularly interesting, in that it illuminates much of the underlying theory of linear algebra. It turns out, that in $\Vect_k$, the product and coproduct are both given by the direct sum $\oplus$, where the direct sum of two $k$-vector spaces $V,W$ is defined as having vectors:
\[V\oplus W=\{(v,w)\mid v\in V,w\in W\},\]
with addition and scalar multiplication given component-wise:
\[c\cdot (v,w) = (c\cdot v,c\cdot w) \hspace{10 mm} (v,w)+(v',w') = (v+v',w+w').\]
When the product and coproduct in $\mcC$ are isomorphic, we call it a \emph{biproduct}. The fact that the direct sum is a product follows from an identical argument as the monoid product: in both cases, we have component-wise operations. We hence leave this as an exercise to the reader. The fact that the direct sum is also a coproduct, however, is more interesting, and is made possible by the existence of $0$ and $+$. More precisely, given $V_i$ for $i=0,1$, we need inclusion maps $\iota_i:V_i\to V$. These are given by $v_0\mapsto (v_0,0)$ and $v_1\mapsto (0,v_1)$. For sets, we did not have a canonical arrow into a Cartesian product from a factor---but because vector spaces are equipped with the special element $0$, we can just define the other component of an included factor as $0$. Similarly, we now need a way to assemble two maps $\varphi_i:V_i\to W$. We now wish to define the combined map $\varphi:V_0\oplus V_1\to W$ so as to satisfy, for the sake of a bijective correspondence, $\iota_i\then \varphi=\varphi_i$. We do so by exploiting linearity:
\[\varphi(v_0,v_1)=\varphi(v_0,0) + \varphi(0,v_1) = \varphi_0(v_0)+\varphi_1(v_1).\]
This cannot be done in the case of typical Cartesian products of sets since there is no way to break up a generic set map $f(u,v)$ into its $u$ and $v$ domain influences. Linearity, however, forces these to be independent!

If $\mcC$ has products and coproducts, then if we have an arrow $f:X_0+ X_1\to Y_0\times Y_1$, then this can be studied via an array of $4$ component maps $f_i^j:X_i\to Y_j$ for $i,j=0,1$. When $\mcC$ has biproducts, this then becomes true for maps $\varphi:X_0\oplus X_1\to Y_0\oplus Y_1$. In the context of vector spaces, this is precisely the idea of a block matrix! More precisely, for a linear map 
\[L:V_0\oplus V_1\to W_0\oplus W_1\] we have a $2\times 2$ array, or \emph{block matrix} whose $ij^\text{th}$ entry is a linear map $V_j\to V_i$. In addition to having biproducts, The category of $k$-vector spaces enjoys even more structure: all of its objects are isomorphic to \emph{bipowers}, i.e. repeated biproducts, of isomorphic copies of a single object: the base field $k$. Recall that, for any vector space $V$, there exists a tuple $\mathcal{B}=(b_i)_{i=1}^n\subset V$, called a \emph{basis}, such that, for any vector $v\in V$, there are unique $c_i\in k$ for which $v=\textstyle\sum_i c_ib_i$. This can be recast as a direct sum as follows. Given a vector $v\in V$, let $kv=\{cv\mid c\in k\}$ be the one dimensional vector space of scalar multiples of $v$. Note that $kv\cong k$ via $v\mapsto 1$. Then, given a basis $\mathcal{B}=(b_i)_{i=1}^n\subset V$, we have the following sequence of isomorphisms, instantiating the direct sum decomposotion of $V$.
\[V \cong \bigoplus_{i=1}^nkb_i\cong k^n\]
The isomorphism ${}_{\mathcal{B}}[-]$ and its inverse $[-]_{\mathcal{B}}$ is given by the following composition of maps. Given a vector $v\in V$, we can uniquely write $v=\sum_ic_ib_i$. We then map $v$ to the tuple $(c_1b_1,\dots,c_nb_n)$ and then to $(c_1,\dots,c_n)$. In turn, given a tuple $(c_1,\dots,c_n)\in k^n$ to the tuple $(c_1b_1,\dots,c_nb_n)$ and then to the sum $\sum_ic_ib_i$. The existence and uniqueness of a linear expression in terms of the basis for any vector is precisely what allows these maps to be mutual inverses. Now, given \emph{any} linear map $L:V\to W$, and a basis $\mathcal{A}$ of $V$ and $\mathcal{B}$ of $W$, we have the following composition: 
\[
\begin{tikzcd}
V \arrow[r,"L"] & W \arrow[d,"\mtrx{\mathcal{B}}{-}{}"] \\
k^m \arrow[u,"\mtrx{}{-}{\mathcal{A}}"] \arrow[r,dotted,"\mtrx{\mathcal{B}}{L}{\mathcal{A}}"'] & k^n
\end{tikzcd}
\]
Note that we used the shorthand $\mtrx{\mathcal{B}}{L}{\mathcal{A}}=\mtrx{}{-}{\mathcal{A}}\then L\then \mtrx{\mathcal{B}}{-}{}$. The map $\mtrx{\mathcal{B}}{L}{\mathcal{A}}$ is the matrix corresponding to $L$ written in terms of the domain basis $\mathcal{A}$ and codomain basis $\mathcal{B}$. Recall that the $ij^\text{th}$ entry $\mtrx{i}{L}{j}$ of this matrix is a linear map $k\to k$, which is just a scalar; more precisely, it is the coefficient of the codomain basis $b_i$ of the image of the domain basis $a_j$ under the linear map $L$. In diagrammatic form, this entry can be encoded as follows.
\[
\begin{tikzcd}
V \arrow[r,"L"] & W \arrow[d] \\
ka_j \arrow[u] \arrow[r,dotted,"\mtrx{i}{L}{j}"'] & kb_i
\end{tikzcd}
\]
Note that we chose the convention that the domain basis goes on the right so as to match the classic matrix composition ordering:
\[\mtrx{\mathcal{B}_2}{L}{\mathcal{B}_1}\mtrx{\mathcal{B}_1}{L'}{\mathcal{B}_0}=\mtrx{\mathcal{B}_2}{L L'}{\mathcal{B}_0}.\]
Products and coproducts in $\mcC$ not only act on objects, but, when they exist, can be seen as functors $\mcC\times\mcC\to\mcC$. More precisely, we map $\mcC\times\mcC$-objects---i.e. pairs $(X,Y)$---respectively to $X\times Y$ and $X+Y$, and $\mcC\times\mcC$-arrows---i.e. pairs $(f,g):(X,Y)\to (X',Y')$---respectively to arrows $X\times Y\to X'\times Y'$ and $X+Y\to X'+Y'$. We define the product arrow in terms of universal properties as follows.
\[
\begin{tikzcd}
& X \arrow[r,"f"] & X' \\
X\times Y \arrow[ur,"\pi_X"] \arrow[dr,"\pi_Y"'] \arrow[r,dashed] & X'\times Y' \arrow[ur,"\pi_{X'}"'] \arrow[dr,"\pi_{Y'}"] &   \\
& Y \arrow[r,"g"'] & Y'   \\
\end{tikzcd}
\]
The case of coproduct is merely dual to the case of product above and is left as an exercise. In the case of $\Set$, these are defined in the intuitive way: $(x,y)\mapsto (fx,gy)$ and $x\mapsto fx, g\mapsto gy$ respectively. In the case of biproducts and a zero object (a simultaneously initial and terminal object)---as is the situation in $\Vect_k$---this can be made even simpler. Since we have a zero object, we can define the \emph{zero morphism} $X\to Y$ for \emph{any} pair $X,Y$ as the following composition:
\[
\begin{tikzcd}
X \arrow[r,dashed] & 0 \arrow[r,dashed] & Y
\end{tikzcd}
\]
Then, since any arrow $X\oplus Y\to X'\oplus Y'$ is merely an arrow for each choice of domain and codomain summand, simply map $(f,g):(X,Y)\to (X',Y')$ to the arrow $X\oplus Y\to X'\oplus Y'$ defined by the components as follows:
\[
\begin{bmatrix}
f : X\to X' & 0 \\
0 & g : Y \to Y'
\end{bmatrix}
\]
Thus the direct sum of linear maps $\oplus_i^n L_i:V_i\to W_i$ is the map $L:\oplus_iV_i\to\oplus_iW_i$ given by the following \emph{block diagonal} matrix.
\[\begin{bmatrix}
L_1 & 0   & \dots & 0 \\ 
0   & L_2 & \dots & 0 \\
\vdots & \vdots &\ddots & \vdots  \\
0 & 0 & \dots & L_n
\end{bmatrix}
\]
Thus, we can define a diagonal matrix as a direct sum of scalar maps $\oplus_i(c_i:k\to k)$.

Note that, although the direct sum of vector spaces involves the product of their unerlying sets, its dimension is the sum of their respective dimensions---more precisely, the basis of the direct sum is the disjoint union of the bases of each summand. This is true for a deep reason to be explained in the next section. What about a vector space whose basis is the product of the bases of some pair of vector spaces? It turns out that there is a universal construction that achieves this. To motivate this construction, let $V$ and $V'$ be vector spaces with bases $\mathcal{A}=(a_j)_{j\in J}$ and $\mathcal{A'}=(a_i)_{i\in I}$. Let $L$ be a linear map, with domain the \emph{set} of vectors $V\times V'$, and $R$ a \emph{bilinear} map with domain $V\times V'$. We then have the following scenarios.
\begin{align*}
    L(v,w) &= \textstyle L(\sum_jc_ja_j,\sum_ic_ia_i) \\ &= \textstyle L(\sum_jc_ja_j,0) + L(0,\sum_ic_ia_i) \\ 
    &=  \textstyle\sum_jc_j L(a_j,0) + \sum_ic_iL(0,a_i) \\
    &= \textstyle \sum_{k\in I+J}c_k L\hat{a}_k
\end{align*}
where we let $\hat{a}_k$ be $(a_j,0)$ for $k\in J$ and $(0,a_i)$ for $k\in I$. This notation is made to transparently imply the idea that a linear map of two arguments is determined by the disjoint union of the bases for these two arguments' spaces. Now consider the case of bilinearity.
\begin{align*}
    R(v,w) &= \textstyle R(\sum_jc_ja_j,\sum_ic_ia_i) \\
    &= \textstyle \sum_i\sum_j c_jc_i R(a_j,a_i) \\
    &= \textstyle\sum_{(i,j)\in I\times J}c_ic_j R(a_j\otimes a_i)
\end{align*}
where the \emph{tensor} $a_j\otimes a_i$ is a formal symbol that represents the ordered pair $(a_j,a_i)$, but now conceived as a generic element of a new domain vector space that we define in order to reconceptualize $R$ as a linear map instead of a bilinear one. Note that $R$ is determined by pairs of the two arguments, and hence will have as basis the Cartesian product of the bases of its factors, or \emph{tensorands}. The tensor product will thus be multiplicative in dimension. We may construct the \emph{tensor product} $V\otimes V'$ explicitly as follows. 
\[V\otimes V'=\textstyle\{\sum_{i,j}c_{ij}(v_i\otimes v'_j)\mid v_i\in V,v_j'\in V',c_{ij}\in k\}/\sim,\] where the equivalence relation encodes the multilinearity that we wish to be preserved by an outgoing linear map. More precisely: 
\[\textstyle[\sum_ic_iv_i]\otimes [\sum_j c'_jv'_j]\sim \sum_{i,j}c_ic'_j(v_i\otimes v_j).\]
A linear map $\tilde{R}:V\otimes V'\to W$ then behaves like a bilinear map $R:V\times V'\to W$:
\begin{align*}
    \textstyle \tilde{R}([\sum_ic_iv_i]\otimes [\sum_j c'_jv'_j]) &= \textstyle \tilde{R}(\sum_{i,j}c_ic'_j(v_i\otimes v_j)) \\
    &=\textstyle \sum_{i,j}c_ic'_j \tilde{R}(v_i\otimes v_j)
\end{align*}
This can be made more precise via a universal property:
\[
\begin{tikzcd}
V\times V' \arrow[d,"\rho"'] \arrow[r,"R"] & W \\
V\otimes V' \arrow[ur,dashed,"\tilde{R}"']
\end{tikzcd}
\]
The map $\rho$ is given by the rule $(v,v')\mapsto v\otimes v'$, and the dashed line, as usual, represents the unique arrow---in $\Vect_k$---that makes the diagram commute. Note that the non-dashed arrows are in this case \emph{not} arrows in $\Vect_k$ but rather are bilinear maps. As usual, this universal property can be recast as a representable functor. More precisely let $\Bilin(V\times V',-):\Vect_k\to\Set$ map a vector space $W$ to the set of bilinear maps $V\times V'\to W$. Then the universal property gives the following natural isomorphism:
\[\Bilin(V\times V',-)\cong \Vect_k(V\otimes V',-).\]
Thus, although the tensor product is neither product nor coproduct in $\Vect_k$, it is nonetheless a universal binary operation on vector spaces, and one that plays the role of multiplication---at the least at the level of dimensionality---relative to the direct sum's role of addition. We will explore this further in the subsequent section.

Another pair of universal constructions of note are so called \emph{equalizers} and their dual \emph{coequalizers}. Both constructions begin with a pair of parallel arrows $f,g:X\to Y$, and ask the following dual questions. The equalizer $\eq(f,g)$ is an arrow $\varphi:A\to X$ for which $\varphi\then f=\varphi\then g$, such that any other arrow $\beta:B\to X$ with the same property must be a composition $\beta=\alpha\then\varphi$ for some $\alpha:B\to A$. This can be expressed as a universal diagram as follows:
\[
\begin{tikzcd}
A \arrow[r,"\varphi"] & X \arrow[r,"f",shift left=0.7ex] \arrow[r,"g"',shift left=-0.7ex] & Y \\
B \arrow[ur,"\beta"'] \arrow[u,dashed,"\alpha"]
\end{tikzcd}
\]
The coequalizer $\coeq(f,g)$ is given by the dual condition:
\[
\begin{tikzcd}
X \arrow[r,"f",shift left=0.7ex] \arrow[r,"g"',shift left=-0.7ex] & Y \arrow[dr,"\omega"'] \arrow[r,"\psi"] & V \arrow[d,dashed,"\nu"]  \\
&& W
\end{tikzcd}
\]
In the case of $\Set$, we will show that the equalizer and coequalizer---using the same variable names as in the diagrams above---can be given via the following formula. 
\begin{align*}
A &= \{x\in X\mid fx = gx\} \\
V &= Y/\sim\text{ where }  y\sim y' \Leftrightarrow [y=fx,y'=gx]
\end{align*}
By construction, these satisfy the commutativity properties. We now prove universality. We first do the equalizer case. Suppose there is some $\beta : B\to X$ for which $\beta\then f=\beta\then g$, i.e. $f(\beta b)=g(\beta b)$ for every $b\in B$. This implies that $\beta b\in A$, and hence that the image of $\beta$ is a subset of $A$. Thus we may simply define $\alpha$ by the rule given by $\beta$, except with codomain $A$. Now consider the coequalizer case; i.e. that there is a map $\omega : Y\to W$ for which $f\then \omega = g\then\omega$, i.e. for which $\omega (fx) = \omega (g x)$ for all $x\in X$. But then this means that $\omega$ can be defined on equivalence classes $[y]$ based on the equivalence relation $\sim$, and hence can be seen as a two step process: first via applying $\psi$, which quotients by $\sim$, and then by applying $\omega$ to the equivalence relation.

In the context of $\Pre$, the equalizer and coequalizer have underlying set given by the set (co)equalizer. The ordering structure on the equalizer $A$ is made to maintain that it is a sub-order of $X$---adding any further relations would cause $\varphi$ to fail to be monotone, and deleting any relations would create an obstruction for maps from $B$ to factor through $A$. In the case of the coequalizer, we must now ask what it means for $[y]\preceq [y']$. Since $\psi$ is monotone, we \emph{must} always have that, when $y\preceq y'$, that $[y]\preceq[y']$. To make this relation well defined under the equivalence class, we define the ordering as follows.
\[\preceq([y],[y'])=\begin{cases} \top & \exists z,z':y\sim z\preceq z' \sim y'\\ \bot & \text{otherwise} \end{cases}\]
As was the case for products and coproducts, $\Pos$ and $\Tot$ inherit their equalizers from $\Pre$---it is easy to see that posets are closed under taking both equalizers and coequalizers, and that total orders are closed under taking equalizers but typically not under coequalizers.

We will not formally discuss (co)equalizers in the context of $\Mon$. The idea would involve defining things in terms of generators so that the relevant arrows become homomorphisms. In the context of $\Vect_k$, given a linear map $L:V\to W$, we define its \emph{kernel} $\ker L$ and \emph{cokernel} $\coker L$ respectively as be the equalizer and coequalizer of the pair $L,0:V\to W$. Set theoretically, we define these as follows.
\begin{align*}
    \ker   L & = \{v\in V\mid Lv=0\} \\
    \coker L & = W/\sim\text{ where } w\sim w' \Leftrightarrow \exists v:w-w'=Lv
\end{align*}
Then, it is easy to check that the equalizer and coequalizer of $L,L':V\to W$ are respectively $\ker(L-L')$ and $\coker(L-L')$. 

We now introduce a highly general dual pair of universal constructions. Let $\mcC$ be a category, serving as a setting, $\Delta$ a small category, serving as a shape, and $\tau:\Delta\to\mcC$ be a $\mcC$-diagram of shape $\Delta$. Define a \emph{cone} $(c,(f_d)_{d\in|\Delta|})$ over $\tau$ as having the data of a $\mcC$-object $c$ and a collection of arrows $f_d:c\to \tau(d)$ for all $\Delta$-objects $d$. Furthermore, this data must satisfy the condition that for all $\Delta$-arrows $i:d\to d'$, the following diagram commutes.
\[
\begin{tikzcd}
c \arrow[d,"f_d"'] \arrow[dr,"f_{d'}"] \\
\tau(d) \arrow[r,"\tau(i)"'] & \tau(d')
\end{tikzcd}
\]
Dually, a \emph{cocone} $(c,(f_d)_{d\in|\Delta|})$ under $\tau$ has an equivalent definition with the exception that the arrows $f_d:\tau(d)\to c$ go the other way. In a context where $\Delta$ has a visually tractable form, we often represent cones and cocones via a single picture. For example, let $\Delta$ be the preorder defined by the following graph.
\[
\begin{tikzcd}
d_1 \arrow[r] & d_2 & d_3 \\
& d_4 \arrow[ul] \arrow[u] \arrow[ur] & d_5 \arrow[u]
\end{tikzcd}
\]
Given the diagram $\tau:\Delta\to\mcC$, a cone over $\tau$ can then be depicted as the following commutative diagram.
\[
\begin{tikzcd} 
c \arrow[dd] \arrow[ddr] \arrow[ddrr] \arrow[dddr] \arrow[dddrr] \\
{} \\
\tau(d_1) \arrow[r] & \tau(d_2) & \tau(d_3) \\
& \tau(d_4) \arrow[ul] \arrow[u] \arrow[ur] & \tau(d_5) \arrow[u]
\end{tikzcd}
\]
By virtue of commutativity, a subset of the legs can determine the cone. In this context, the following diagram uniquely determines the one above.
\[
\begin{tikzcd} 
c \arrow[dddr] \arrow[dddrr] \\
{} \\
\tau(d_1) \arrow[r] & \tau(d_2) & \tau(d_3) \\
& \tau(d_4) \arrow[ul] \arrow[u] \arrow[ur] & \tau(d_5) \arrow[u]
\end{tikzcd}
\]
Now consider a cocone under $\tau$.
\[
\begin{tikzcd} 
c \\
{} \\
\tau(d_1) \arrow[r] \arrow[uu] & \tau(d_2) \arrow[uul] & \tau(d_3) \arrow[uull] \\
& \tau(d_4) \arrow[ul] \arrow[u] \arrow[ur] \arrow[uuul] & \tau(d_5) \arrow[u] \arrow[uuull]
\end{tikzcd}
\]
This diagram too can be simplified, albeit differently than in the cone case. 
\[
\begin{tikzcd} 
c \\
{} \\
\tau(d_1) \arrow[r] & \tau(d_2) \arrow[uul] & \tau(d_3) \arrow[uull] \\
& \tau(d_4) \arrow[ul] \arrow[u] \arrow[ur]  & \tau(d_5) \arrow[u]
\end{tikzcd}
\]
We now define a pair of notions that directly generalize products and coproducts. Let ${\mcC}/\tau$ be the category with objects cones over $\tau$ and arrows $(c,(f_d))\to (c',(f'_d))$ $\mcC$-arrows $\varphi:A\to A'$ for which $f'_d=\varphi\then f_d$. Then the \emph{limit} of $\tau$, denoted $\lim\tau$ is the terminal object of $\mcC/\varphi$. Dually, define the category $\tau/\mcC$ as having objects cocones under $\tau$ and arrows $(c,(f_d))\to (c',(f'_d))$ $\mcC$-arrows $\varphi:A\to A'$ for which $f'_d= f_d\then\varphi $. Then the \emph{colimit} of $\tau$, denoted $\colim\tau$, is the initial object of $\tau/\mcC$. Now let $\Cone_\tau:\mcC\op\to\Set$ map a $\mcC$-object $A$ to the set of cones over $\tau$, i.e. $\mcC/\tau$-objects, with apex $A$. Dually, let $\Cocone_\tau:\mcC\to\Set$ map a $\mcC$-object $A$ to the set of cocones under $\tau$, i.e. $\tau/\mcC$-objects, with apex $A$. We then have the following isomorphisms.
\begin{align*}
    \Cone_\tau &\cong \mcC(-,\lim\tau ) \\
    \Cocone_\tau &\cong \mcC(\colim\tau,-)
\end{align*}
Let $\Delta$ be the discrete category on $\underline{2}$ and $\tau(i)=X_i$. We then have the following.
\begin{align*}
    \mcC/\tau&=\mcC/(X_0,X_1) \\ \tau/\mcC&=(X_0,X_1)/\mcC\\
    \Cone_\tau &= \Cone_{X_0,X_1} \\
    \Cocone_\tau &=\Cocone_{X_0,X_1} \\ 
    \lim\tau &= X_0\times X_1 \\
    \colim\tau &=X_0+X_1
\end{align*}
Now let $\Delta$ be given by the following quiver.
\[
\begin{tikzcd}
d \arrow[r,shift left=-0.7ex,"1"']\arrow[r,shift left=0.7ex,"0"]&d' 
\end{tikzcd}
\]
Let $\tau$ be given by $0\mapsto f,1\mapsto g$. Then $\lim\tau=\eq(f,g)$ and $\colim\tau=\coeq(f,g)$. In addition to these two common shapes, there are two more pairs that are arise sufficiently frequently that they have names. Denote respectively by $\to\ot$ and $\ot\to$ the following two diagrams.
\[
\begin{tikzcd}
d'\arrow[r,"0"] & d & d''\arrow[l,"1"'] & & d' & d \arrow[r,"1"] \arrow[l,"0"'] & d''
\end{tikzcd}
\]
If $\tau:[\to\ot]\to\mcC$, we call $\lim\tau$ a \emph{pullback}, and if $\sigma:[\ot\to]\to\mcC$, we call $\colim\sigma$ a \emph{pushout}. The other two configurations---$\colim\tau$ and $\lim\sigma$---are seldom encountered. Letting $\tau$ and $\sigma$ both be given by the rules $d'\mapsto X,d\mapsto Z,d''\mapsto Y,0\mapsto f,1\mapsto g$, we often write $\lim\tau=X\times_ZY$ and $\colim\sigma=X+_ZY$, and often refer to them as \emph{fibered} products and coproducts, respectively. In this context, we often depict pullbacks and pushouts as follows.
\[
\begin{tikzcd}
X\times_Z Y  \arrow[dr, phantom, "\lrcorner", very near start]  \arrow[r] \arrow[d] & X \arrow[d,"f"] & & & Z \arrow[r,"f"] \arrow[d,"g"'] & X \arrow[d] \\
Y \arrow[r,"g"'] & Z & & & Y \arrow[r] & X+_Z Y  \arrow[ul, phantom, "\ulcorner", very near start]
\end{tikzcd}
\]
The corner symbols are used to distinguish these two situations, both from each other and from a mere commutative square. We will only cover examples of pullbacks and pushouts in $\Set$. In general, these are given by the following formulae.
\begin{align*}
    X\times_Z Y &= (X\times Y)|_{fx=gy} \\
    X+_Z Y      &= (X+Y)/[fz\sim gz]
\end{align*}
This has some interesting special cases. For example, suppose $A,B$ are both subsets of $S$ and we consider the pullback of the inclusion maps $\iota_A,\iota_B$. Then
\[A\times_S B=A\times B|_{\iota_A a=\iota_Bb}=\{(s,s)\mid s\in A\cap B\}\cong A\cap B.\]
Hence we have the set intersection. Now, with this intersection in hand, consider $A\cap B$ with inclusions $\iota'_A,\iota'_B$ to $A,B$. Then the pushout is the classic union:
\[A+_{A\cap B}B=A+B/[\iota_A'z\sim \iota_B'z]=A\cup B.\]
We now consider a differently flavored example. Let $f:X\to Y$ be a map and $\iota : S\to Y$ a subset inclusion. Then the pullback is given by the preimage:
\[X\times_Y S=X\times S|_{fx=\iota s}=\{x\in X\mid fx\in S\}=f^*(S).\]
We end this section with a remark about limits and colimits of diagrams of shape given by the thin category $(\NN,\leq)$, which we denote by $\omega$, and depict as follows:
\[0\to 1\to 2\to \cdots \to n\to\cdots \]
Classically, limits and colimits of diagrams of this shape have respectively been called \emph{inverse limits} and \emph{direct limits}. We will avoid this terminology since it flips the verbal associations of the general limit and colimit terminology.

Let $\tau:\omega\to\Set$ be given on objects by $n\mapsto\mathbf{n}=\{1,\dots,n\}$ and on arrows as inclusion maps. We now show why $\colim\tau\cong\NN$.
\[ 
\begin{tikzcd}
\mathbf{0}\arrow[r]\arrow[dd] \arrow[dddrr] & \mathbf{1}\arrow[r]\arrow[ddl] \arrow[dddr] &\cdots \arrow[r]&\mathbf{n}\arrow[r]\arrow[ddlll,"\iota_n"]\arrow[dddl,"f_n"] &\cdots \\
\\
\NN \arrow[drr,dashed,"f"']\\
& & A
\end{tikzcd}
\]
The universal cocone legs are inclusions. We must now construct a map $f:\NN\to A$. By defining this via the rule $n\mapsto f_n(n)$, we have that $\iota_n\then f=f_n$. This is well defined by the cone condition, which forces $f_n(i)=f_m(i)$ whenever $i<m<n$.

We now consider a limit over a diagram of such a shape. Given some set $X$, let $\tau:\omega\op \to\Set$ be given on objects by $n\mapsto X^n$ and on arrows as projections $\eta_n:X^n\to X^{n-1}::(x_1,\dots,x_{n-1},x_n)\mapsto (x_1,\dots,x_{n-1})$. We show that $\lim\tau\cong X^{\NN}$.
\[ 
\begin{tikzcd}
\star & X\arrow[l] &\cdots \arrow[l]&X^n\arrow[l] &\cdots \arrow[l]\\
\\
 X^{\NN}  \arrow[uu] \arrow[uur] \arrow[uurrr,"\Pi_n"'] \\
& & A \arrow[uuull]\arrow[uuul]\arrow[uuur,"f_n"'] \arrow[ull,dashed,"f"]
\end{tikzcd}
\]
Define the universal cone leg $\Pi_n$ by the map $s\mapsto s(n)$. A map $f:A\to X^{\NN}$ is equivalent to a map $F:\NN\times A\to X$. Let $\pi_n:X^n\to X$ be given by the projection onto the final factor. We then define $F(n,-)$ as the following composition.
\[
\begin{tikzcd}
A\arrow[r,"f_n"] \arrow[dr,"{F(n,-)}"'] & X^n \arrow[d,"\pi_n"] \\
& X 
\end{tikzcd}
\]
It turns out that all limits are in some sense generated by products and equalizers; and, dually, all colimits by coproducts and coequalizers. We conclude this section by stating without proof a result that formalizes this intuition.

\begin{prop}
Let $\mcC$ be a category with products and equalizers. Then, given any diagram $\tau:\Delta\to\mcC$, $\lim\tau$ exists in $\mcC$.
\end{prop}